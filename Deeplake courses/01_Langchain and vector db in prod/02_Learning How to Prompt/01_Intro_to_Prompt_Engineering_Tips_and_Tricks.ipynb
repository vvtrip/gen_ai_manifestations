{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae33dd83-297d-443f-a08f-1c92df119c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b818746b-0734-439b-8488-cbbd4a15398e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv('file.env'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d0c8b92-788f-46c5-9ae3-ea068e0124d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain-> 0.2.8 openai-> 1.35.14\n"
     ]
    }
   ],
   "source": [
    "import openai,langchain\n",
    "print(\"langchain->\",langchain.__version__, \"openai->\",openai.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbec892d-cd08-4ec3-964d-3ab980af33e5",
   "metadata": {},
   "source": [
    "# Role  Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac664de-deba-4206-9bd9-706d3959557d",
   "metadata": {},
   "source": [
    "Role prompting involves asking the LLM to assume a specific role or identity before performing a given task, such as acting as a copywriter. This can help guide the model's response by providing a context or perspective for the task. To work with role prompts, you could iteratively:\n",
    "\n",
    "1- Specify the role in your prompt, e.g., \"As a copywriter, create some attention-grabbing taglines for AWS services.\"\n",
    "\n",
    "2 - Use the prompt to generate an output from an LLM.\n",
    "\n",
    "3 - Analyze the generated response and, if necessary, refine the prompt for better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7b088b4-0caf-459c-919f-64ed6f5ea4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theme: interstellar travel\n",
      "Year: 3030\n",
      "AI-generated song title: \n",
      "\"Galactic Odyssey: Journey to 3030\"\n"
     ]
    }
   ],
   "source": [
    "# In this example, the LLM is asked to act as a futuristic robot band \n",
    "# conductor and suggest a song title related to the given theme and year\n",
    "\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model = \"gpt-3.5-turbo-instruct\", temperature=0)\n",
    "\n",
    "template = \"\"\"\"\n",
    "            As a futuristic robot band conductor, I need you to help me come up with a song title.\n",
    "            What's a cool song title for a song about {theme} in the year {year}?\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables = [\"theme\", \"year\"],\n",
    "    template = template)\n",
    "\n",
    "input_data = {\"theme\":\"interstellar travel\",\"year\":\"3030\"}\n",
    "\n",
    "chain = LLMChain(llm = llm, prompt=prompt)\n",
    "\n",
    "response = chain.invoke(input_data)\n",
    "\n",
    "print(\"Theme: interstellar travel\")\n",
    "print(\"Year: 3030\")\n",
    "print(\"AI-generated song title:\", response['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b377d40-48d1-4620-a731-0c10ec428404",
   "metadata": {},
   "source": [
    "This is a good prompt for several reasons:\n",
    "\n",
    "- **Clear instructions:** The prompt is phrased as a clear request for help in generating a song title, and it specifies the context: \"As a futuristic robot band conductor.\" This helps the LLM understand that the desired output should be a song title related to a futuristic scenario.\n",
    "\n",
    "- **Specificity:** The prompt asks for a song title that relates to a specific theme and a specific year, \"{theme} in the year {year}.\" This provides enough context for the LLM to generate a relevant and creative output. The prompt can be adapted for different themes and years by using input variables, making it versatile and reusable.\n",
    "\n",
    "- **Open-ended creativity:** The prompt allows for open-ended creativity, as it doesn't limit the LLM to a particular format or style for the song title. The LLM can generate a diverse range of song titles based on the given theme and year.\n",
    "Focus on the task: The prompt is focused solely on generating a song title, making it easier for the LLM to provide a suitable output without getting sidetracked by unrelated topics.\n",
    "\n",
    "These elements help the LLM understand the user's intention and generate a suitable response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea73d1c-596d-4327-9fb8-a3e69ade989d",
   "metadata": {},
   "source": [
    "# Few Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "becf2f8f-9637-49f3-8fc3-39547d2c8c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colour purple\n",
      "Emotion  royalty\n"
     ]
    }
   ],
   "source": [
    "# Few Shot Prompting In the next example, the LLM is asked to provide the emotion \n",
    "# associated with a given color based on a few examples of color-emotion pairs:\n",
    "from langchain import FewShotPromptTemplate\n",
    "examples = [\n",
    "    {\"color\": \"red\", \"emotion\": \"passion\"},\n",
    "    {\"color\": \"blue\", \"emotion\": \"serenity\"},\n",
    "    {\"color\": \"green\", \"emotion\": \"tranquility\"},\n",
    "]\n",
    "\n",
    "example_formatter_template = \"\"\"\n",
    "Color: {color}\n",
    "Emotion: {emotion}\\n\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"color\", \"emotion\"],\n",
    "    template=example_formatter_template,\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples = examples,\n",
    "    example_prompt = example_prompt,\n",
    "    prefix = \"Here are some examples of colors and the emotions associated with them:\\n\\n\",\n",
    "    suffix=\"\\n\\nNow, given a new color, identify the emotion associated with it:\\n\\nColor: {input}\\nEmotion:\",\n",
    "    input_variables=  [\"input\"],\n",
    "    example_separator = \"\\n\")\n",
    "\n",
    "formatted_prompt = few_shot_prompt.format(input=\"purple\")\n",
    "\n",
    "chain = LLMChain(llm = llm, prompt=PromptTemplate(template=formatted_prompt))\n",
    "\n",
    "response  = chain.invoke({})\n",
    "\n",
    "print(\"Colour\",\"purple\")\n",
    "print(\"Emotion\",response['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0955cb35-5f00-4e04-8784-db6a00eb4828",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
