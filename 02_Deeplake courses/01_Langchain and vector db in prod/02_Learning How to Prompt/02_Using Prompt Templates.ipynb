{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b7693d1-2efd-4076-848e-b04b5aa9db5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain, PromptTemplate\n",
    "import openai, langchain\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe3fe21d-ee3c-45f1-bf59-bf0d47b97faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv('newenv.env'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d88647f-779f-4184-a55b-46c97eab7e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.13'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langchain.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23f276ca-2f73-44fa-a99d-6f6225904e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.40.6'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d939047b-b6b6-43fd-9828-517daeebfc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the realm where coders dwell,  \n",
      "There’s a magic trick, I’ll tell you well,  \n",
      "With whispers soft and echoes clear,  \n",
      "It’s recursion that we hold so dear.  \n",
      "\n",
      "A function calls—a friend, a twin,  \n",
      "To solve a problem from within,  \n",
      "“Dear self,” it says, “come play a part,  \n",
      "For in your hands lies the clever art.”  \n",
      "\n",
      "But heed this tale, of paths so grand,  \n",
      "A base case waits, a guiding hand.  \n",
      "For without it, looping round and round,  \n",
      "A never-ending maze is found.  \n",
      "\n",
      "Imagine a mountain, steep and vast,  \n",
      "Where reaching the peak involves a past.  \n",
      "Step by step, the journey unfolds,  \n",
      "Each call, a story of courage bold.  \n",
      "\n",
      "“Look in the mirror,” recursion sings,  \n",
      "“To find your answer, know what this brings.  \n",
      "Divide the task, make it small,  \n",
      "Each little piece—a clearer call.”  \n",
      "\n",
      "Factorials follow this recursive dance,  \n",
      "Five! Oh the wonder, give it a chance:  \n",
      "Five times four, and four must call,  \n",
      "Three times two, till one stands tall.  \n",
      "\n",
      "So stacks arise, like towers of dreams,  \n",
      "Each frame a layer, unraveling seams,  \n",
      "Understanding builds, like blocks of clay,  \n",
      "In the heart of the code, recursion will play.  \n",
      "\n",
      "With elegance woven in logic’s embrace,  \n",
      "Recursion creates a beautiful space.  \n",
      "To solve the complex, the deep, the wide,  \n",
      "In the folds of its loops, let your thoughts reside.  \n",
      "\n",
      "So here’s to the functions that call and return,  \n",
      "In the dance of recursion, we endlessly learn.  \n",
      "For in every call, both near and far,  \n",
      "We discover the magic—our own guiding star.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9a6d74b-63b8-420c-8c05-5aaf70c457fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of October 2023, the top five highest-grossing movies of all time by worldwide box office revenue are:\n",
      "\n",
      "1. **Avatar** (2009) - Directed by James Cameron, this sci-fi epic has grossed over $2.9 billion.\n",
      "2. **Avengers: Endgame** (2019) - Directed by Anthony and Joe Russo, this Marvel superhero film has grossed approximately $2.798 billion.\n",
      "3. **Titanic** (1997) - Also directed by James Cameron, this romantic drama has earned around $2.2 billion.\n",
      "4. **Star Wars: The Force Awakens** (2015) - Directed by J.J. Abrams, this installment of the Star Wars saga has grossed about $2.068 billion.\n",
      "5. **Avengers: Infinity War** (2018) - Directed by Anthony and Joe Russo, this film has earned around $2.048 billion.\n",
      "\n",
      "Please note that these figures are subject to change as movies are re-released and box office numbers are updated.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "messages= [\n",
    "    (\"system\", \"You are an expert assistant about movies.\"),\n",
    "    (\"human\", \"Can you tell top 5 movies of all time by revenue?\")\n",
    "]\n",
    "\n",
    "print(llm.invoke(messages).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fbcfb0a-c74a-47e6-973f-1715f0f9a17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.llms import OpenAI\n",
    "# llm = OpenAI(model = \"gpt-3.5-turbo-instruct\", temperature=0) #gpt-4o-mini, gpt-3.5-turbo, gpt-4o are chat models so use ChatOpenAI for those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5f320a8-ddb8-44c0-97fb-80340838705f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the main advantage of quantum computing over classical computing?\n",
      "Answer: The main advantage of quantum computing over classical computing is its ability to solve complex problems faster due to its use of quantum mechanics.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"Answer the question based on the context below. If the\n",
    "question cannot be answered using the information provided, answer\n",
    "with \"I don't know\".\n",
    "Context: Quantum computing is an emerging field that leverages quantum mechanics to solve complex problems faster than classical computers.\n",
    "...\n",
    "Question: {query}\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "# Create the LLMChain for the prompt\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "# Set the query you want to ask\n",
    "input_data = {\"query\": \"What is the main advantage of quantum computing over classical computing?\"}\n",
    "\n",
    "# Run the LLMChain to get the AI-generated answer\n",
    "response = chain.run(input_data)\n",
    "\n",
    "print(\"Question:\", input_data[\"query\"])\n",
    "print(\"Answer:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2372b6e-9d95-4715-a157-4ea88a8442c5",
   "metadata": {},
   "source": [
    "To create a PromptTemplate object, two arguments are required:\n",
    "\n",
    "- input_variables: A list of variable names in the template; in this case, it includes only the query.\n",
    "- template: The template string containing formatted text and placeholders.\n",
    "\n",
    "After creating the PromptTemplate object, it can be used to produce prompts with specific questions by providing input data. The input data is a dictionary where the key corresponds to the variable name in the template. The resulting prompt can then be passed to a language model to generate answers.- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e30783-36c7-4676-b07e-1e142d136616",
   "metadata": {},
   "source": [
    "# FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "016fa443-8bd8-4f12-ac67-fa31fa1cc696",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "232c9afb-724c-4823-89ab-8b2085d4fbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animal: tiger  \n",
      "Habitat: tropical rainforests, grasslands, and mangrove swamps\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "    {\"animal\": \"lion\", \"habitat\": \"savanna\"},\n",
    "    {\"animal\": \"polar bear\", \"habitat\": \"Arctic ice\"},\n",
    "    {\"animal\": \"elephant\", \"habitat\": \"African grasslands\"}\n",
    "]\n",
    "\n",
    "example_template = \"\"\"\n",
    "Animal: {animal}\n",
    "Habitat: {habitat}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"animal\", \"habitat\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "dynamic_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Identify the habitat of the given animal\",\n",
    "    suffix=\"Animal: {input}\\nHabitat:\",\n",
    "    input_variables=[\"input\"],\n",
    "    example_separator=\"\\n\\n\",\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=dynamic_prompt)\n",
    "\n",
    "input_data = {\"input\": \"tiger\"}\n",
    "response = chain.run(input_data)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3442377-b9ea-4b0e-a10c-ae5f63854bd1",
   "metadata": {},
   "source": [
    "Additionally, you can also save your PromptTemplate to a file in your local filesystem in JSON or YAML format:\n",
    "\n",
    "     prompt_template.save(\"awesome_prompt.json\")\n",
    "\n",
    "and load it back \n",
    "\n",
    "    from langchain.prompts import load_prompt\n",
    "    loaded_prompt = load_prompt(\"awesome_prompt.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26dfe111-2803-48c9-a489-6bfec0a3f408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start by mastering the art of confusing your friends with Schrödinger jokes. Then, dive into some textbooks that make you question your sanity!\n"
     ]
    }
   ],
   "source": [
    "#sarcasm example\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"How do I become a better programmer?\",\n",
    "        \"answer\": \"Try talking to a rubber duck; it works wonders.\"\n",
    "    }, {\n",
    "        \"query\": \"Why is the sky blue?\",\n",
    "        \"answer\": \"It's nature's way of preventing eye strain.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "example_template = \"\"\"\n",
    "User: {query}\n",
    "AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "prefix = \"\"\"The following are excerpts from conversations with an AI\n",
    "assistant. The assistant is typically sarcastic and witty, producing\n",
    "creative and funny responses to users' questions. Here are some\n",
    "examples: \n",
    "\"\"\"\n",
    "\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "AI: \"\"\"\n",
    "\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=few_shot_prompt_template)\n",
    "\n",
    "# Run the LLMChain with input_data\n",
    "input_data = {\"query\": \"How can I learn quantum computing?\"}\n",
    "response = chain.run(input_data)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbd4bc8-abc1-4cc8-b5a7-710d5229376c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9358d9d5-4e16-47c7-b684-94fbbdb86e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
