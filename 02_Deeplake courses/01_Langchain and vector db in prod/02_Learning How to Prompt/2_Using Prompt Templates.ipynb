{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b7693d1-2efd-4076-848e-b04b5aa9db5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain, PromptTemplate\n",
    "import openai, langchain\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe3fe21d-ee3c-45f1-bf59-bf0d47b97faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv('file.env'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d88647f-779f-4184-a55b-46c97eab7e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.13'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langchain.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23f276ca-2f73-44fa-a99d-6f6225904e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.40.6'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d939047b-b6b6-43fd-9828-517daeebfc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the land of code where logic reigns,  \n",
      "A curious dance unfolds in chains,  \n",
      "Where functions call themselves with grace,  \n",
      "A wondrous loop in a boundless space.  \n",
      "\n",
      "Behold the tale of a mystical door,  \n",
      "To solve a problem, it opens more.  \n",
      "“Step inside!” whispers the function bright,  \n",
      "To unravel the mystery hidden from sight.  \n",
      "\n",
      "First, it asks, “What do you seek to find?”  \n",
      "A complex query, its answer entwined.  \n",
      "“Let’s break it down,” the function so wise,  \n",
      "Into smaller pieces, a clever disguise.  \n",
      "\n",
      "With each gentle call, a piece they unfold,  \n",
      "Until the base case, the truth to behold.  \n",
      "The simplest form, it knows it must stop,  \n",
      "Here lies the answer, the peak of the crop.  \n",
      "\n",
      "Now back through the layers, the answers align,  \n",
      "Like ripples in water, a shimmering line.  \n",
      "Each call returns to where it begun,  \n",
      "Building the answer, the journey now spun.  \n",
      "\n",
      "Oh, recursion, you magical thread,  \n",
      "In problem-solving, you lead where we're led.  \n",
      "With elegance woven in each nested call,  \n",
      "You transform the complex, enchanting us all.  \n",
      "\n",
      "So fear not the depths of this looping embrace,  \n",
      "For in each repetition, we find our own place.  \n",
      "With courage and clarity, let’s conquer the task,  \n",
      "In the realm of recursion, just dare to ask!\n"
     ]
    }
   ],
   "source": [
    "# from openai import OpenAI\n",
    "# client = OpenAI()\n",
    "\n",
    "# completion = client.chat.completions.create(\n",
    "#   model=\"gpt-4o-mini\",\n",
    "#   messages=[\n",
    "#     {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "#     {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "#   ]\n",
    "# )\n",
    "# print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e9a6d74b-63b8-420c-8c05-5aaf70c457fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of October 2023, the top five highest-grossing movies of all time by worldwide box office revenue are:\n",
      "\n",
      "1. **Avatar** (2009) - Directed by James Cameron, this sci-fi epic has grossed over $2.9 billion.\n",
      "2. **Avengers: Endgame** (2019) - Directed by Anthony and Joe Russo, this Marvel superhero film has grossed approximately $2.798 billion.\n",
      "3. **Titanic** (1997) - Also directed by James Cameron, this romantic drama has earned around $2.2 billion.\n",
      "4. **Star Wars: The Force Awakens** (2015) - Directed by J.J. Abrams, this installment of the Star Wars saga has grossed about $2.068 billion.\n",
      "5. **Avengers: Infinity War** (2018) - Directed by Anthony and Joe Russo, this film has earned around $2.048 billion.\n",
      "\n",
      "Please note that box office figures are constantly changing due to re-releases and new films, so it's always good to check for the most current information.\n"
     ]
    }
   ],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "# llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "# messages= [\n",
    "#     (\"system\", \"You are an expert assistant about movies.\"),\n",
    "#     (\"human\", \"Can you tell top 5 movies of all time by revenue?\")\n",
    "# ]\n",
    "\n",
    "# print(llm.invoke(messages).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5fbcfb0a-c74a-47e6-973f-1715f0f9a17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2703f4c5-564d-4e70-85d1-d9f701ea1590",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model = \"gpt-3.5-turbo-instruct\", temperature=0) #gpt-4o-mini, gpt-3.5-turbo, gpt-4o are chat models so not compatible for folowing tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5f320a8-ddb8-44c0-97fb-80340838705f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the main advantage of quantum computing over classical computing?\n",
      "Answer: Quantum computing is able to solve complex problems faster than classical computers.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"Answer the question based on the context below. If the\n",
    "question cannot be answered using the information provided, answer\n",
    "with \"I don't know\".\n",
    "Context: Quantum computing is an emerging field that leverages quantum mechanics to solve complex problems faster than classical computers.\n",
    "...\n",
    "Question: {query}\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "# Create the LLMChain for the prompt\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "# Set the query you want to ask\n",
    "input_data = {\"query\": \"What is the main advantage of quantum computing over classical computing?\"}\n",
    "\n",
    "# Run the LLMChain to get the AI-generated answer\n",
    "response = chain.run(input_data)\n",
    "\n",
    "print(\"Question:\", input_data[\"query\"])\n",
    "print(\"Answer:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2372b6e-9d95-4715-a157-4ea88a8442c5",
   "metadata": {},
   "source": [
    "To create a PromptTemplate object, two arguments are required:\n",
    "\n",
    "- input_variables: A list of variable names in the template; in this case, it includes only the query.\n",
    "- template: The template string containing formatted text and placeholders.\n",
    "\n",
    "After creating the PromptTemplate object, it can be used to produce prompts with specific questions by providing input data. The input data is a dictionary where the key corresponds to the variable name in the template. The resulting prompt can then be passed to a language model to generate answers.- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e30783-36c7-4676-b07e-1e142d136616",
   "metadata": {},
   "source": [
    "# FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "016fa443-8bd8-4f12-ac67-fa31fa1cc696",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "232c9afb-724c-4823-89ab-8b2085d4fbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animal: tiger  \n",
      "Habitat: tropical rainforests, grasslands, and mangrove swamps\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "    {\"animal\": \"lion\", \"habitat\": \"savanna\"},\n",
    "    {\"animal\": \"polar bear\", \"habitat\": \"Arctic ice\"},\n",
    "    {\"animal\": \"elephant\", \"habitat\": \"African grasslands\"}\n",
    "]\n",
    "\n",
    "example_template = \"\"\"\n",
    "Animal: {animal}\n",
    "Habitat: {habitat}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"animal\", \"habitat\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "dynamic_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Identify the habitat of the given animal\",\n",
    "    suffix=\"Animal: {input}\\nHabitat:\",\n",
    "    input_variables=[\"input\"],\n",
    "    example_separator=\"\\n\\n\",\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=dynamic_prompt)\n",
    "\n",
    "input_data = {\"input\": \"tiger\"}\n",
    "response = chain.run(input_data)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3442377-b9ea-4b0e-a10c-ae5f63854bd1",
   "metadata": {},
   "source": [
    "Additionally, you can also save your PromptTemplate to a file in your local filesystem in JSON or YAML format:\n",
    "\n",
    "     prompt_template.save(\"awesome_prompt.json\")\n",
    "\n",
    "and load it back \n",
    "\n",
    "    from langchain.prompts import load_prompt\n",
    "    loaded_prompt = load_prompt(\"awesome_prompt.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "26dfe111-2803-48c9-a489-6bfec0a3f408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start by mastering the art of confusing your friends at parties. Then, dive into some textbooks that make you question your sanity!\n"
     ]
    }
   ],
   "source": [
    "#sarcasm example\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"How do I become a better programmer?\",\n",
    "        \"answer\": \"Try talking to a rubber duck; it works wonders.\"\n",
    "    }, {\n",
    "        \"query\": \"Why is the sky blue?\",\n",
    "        \"answer\": \"It's nature's way of preventing eye strain.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "example_template = \"\"\"\n",
    "User: {query}\n",
    "AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "prefix = \"\"\"The following are excerpts from conversations with an AI\n",
    "assistant. The assistant is typically sarcastic and witty, producing\n",
    "creative and funny responses to users' questions. Here are some\n",
    "examples: \n",
    "\"\"\"\n",
    "\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "AI: \"\"\"\n",
    "\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=few_shot_prompt_template)\n",
    "\n",
    "# Run the LLMChain with input_data\n",
    "input_data = {\"query\": \"How can I learn quantum computing?\"}\n",
    "response = chain.run(input_data)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbd4bc8-abc1-4cc8-b5a7-710d5229376c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
